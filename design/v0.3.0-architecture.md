# Toonify MCP v0.3.0 Architecture Design

**Version**: 0.3.0
**Target Release**: 2025-12-27
**Goal**: Achieve 95%+ token savings through advanced optimizations

---

## üéØ Feature Overview

### New Capabilities

1. **Prompt Caching Integration** (Priority: HIGH)
   - Add cache_control breakpoints to optimized content
   - Structure prompts for maximum cache hits
   - Expected: 90% ‚Üí 94% token savings

2. **Multilingual Tokenizer** (Priority: HIGH)
   - Language detection (English, Spanish, Chinese, Japanese, Tamil, Arabic, etc.)
   - Language-specific token multipliers
   - Accurate token estimation across languages

3. **Multi-Model Optimization** (Priority: MEDIUM)
   - Model-specific optimization strategies (Claude, GPT-4, Gemini)
   - Format selection based on model preferences
   - Model detection from environment/config

4. **Grammar-Constrained Decoding** (Priority: MEDIUM)
   - TOON grammar schema definition
   - Output validation hints
   - Reduce retry overhead

---

## üìê Architecture Changes

### New Module Structure

```
src/
‚îú‚îÄ‚îÄ optimizer/
‚îÇ   ‚îú‚îÄ‚îÄ token-optimizer.ts          (existing - refactor)
‚îÇ   ‚îú‚îÄ‚îÄ types.ts                    (existing - extend)
‚îÇ   ‚îú‚îÄ‚îÄ caching/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache-optimizer.ts      (NEW)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache-types.ts          (NEW)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cache-strategies.ts     (NEW)
‚îÇ   ‚îú‚îÄ‚îÄ multilingual/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ language-detector.ts    (NEW)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tokenizer-adapter.ts    (NEW)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ language-profiles.ts    (NEW)
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model-detector.ts       (NEW)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model-profiles.ts       (NEW)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ format-selector.ts      (NEW)
‚îÇ   ‚îî‚îÄ‚îÄ grammar/
‚îÇ       ‚îú‚îÄ‚îÄ toon-grammar.ts         (NEW)
‚îÇ       ‚îî‚îÄ‚îÄ schema-validator.ts     (NEW)
‚îú‚îÄ‚îÄ metrics/
‚îÇ   ‚îî‚îÄ‚îÄ metrics-collector.ts        (existing - extend)
‚îú‚îÄ‚îÄ server/
‚îÇ   ‚îî‚îÄ‚îÄ mcp-server.ts               (existing - minor changes)
‚îî‚îÄ‚îÄ index.ts                        (existing - minor changes)

hooks/
‚îî‚îÄ‚îÄ post-tool-use.ts                (existing - refactor to use new modules)
```

---

## üîß Detailed Design

### 1. Prompt Caching Integration

#### New Types (`src/optimizer/caching/cache-types.ts`)

```typescript
export interface CacheConfig {
  enabled: boolean;
  provider: 'anthropic' | 'openai' | 'auto';
  ttl?: '5min' | '1hour'; // Anthropic cache TTLs
  cacheStaticPrompts: boolean;
}

export interface CachedContent {
  staticPrefix: string;  // Cacheable system instructions
  dynamicContent: string; // Non-cacheable user data
  cacheBreakpoint: boolean;
}

export interface CacheMetrics {
  cacheHits: number;
  cacheMisses: number;
  cacheHitRate: number;
  estimatedCacheSavings: number; // tokens
}
```

#### Cache Optimizer (`src/optimizer/caching/cache-optimizer.ts`)

```typescript
export class CacheOptimizer {
  constructor(private config: CacheConfig) {}

  /**
   * Wrap optimized TOON content with cache-friendly structure
   */
  wrapWithCaching(
    toonContent: string,
    toolName: string,
    format: 'json' | 'csv' | 'yaml'
  ): CachedContent {
    // Static prefix (cacheable for 1 hour)
    const staticPrefix = `[SYSTEM] TOON Format Data from ${toolName}

TOON is a token-efficient format:
- Arrays: name[size]{fields}: row1,row2
- Objects: key: value
- Nested: parent.child: value

Source Format: ${format.toUpperCase()}
`;

    // Dynamic content (cache breakpoint here)
    const dynamicContent = `\n[DATA]\n${toonContent}`;

    return {
      staticPrefix,
      dynamicContent,
      cacheBreakpoint: true
    };
  }

  /**
   * Format for Anthropic cache_control
   */
  formatForAnthropic(cached: CachedContent): any[] {
    return [
      {
        type: 'text',
        text: cached.staticPrefix,
        cache_control: { type: 'ephemeral' }
      },
      {
        type: 'text',
        text: cached.dynamicContent
      }
    ];
  }
}
```

---

### 2. Multilingual Tokenizer

#### Language Profiles (`src/optimizer/multilingual/language-profiles.ts`)

```typescript
export interface LanguageProfile {
  code: string;
  name: string;
  tokenMultiplier: number; // Relative to English
  detectionPatterns: RegExp[];
}

export const LANGUAGE_PROFILES: LanguageProfile[] = [
  {
    code: 'en',
    name: 'English',
    tokenMultiplier: 1.0,
    detectionPatterns: [/^[a-zA-Z0-9\s.,!?;:'"()-]+$/]
  },
  {
    code: 'es',
    name: 'Spanish',
    tokenMultiplier: 1.7, // From research
    detectionPatterns: [/[√°√©√≠√≥√∫√º√±¬ø¬°]/i]
  },
  {
    code: 'zh',
    name: 'Chinese',
    tokenMultiplier: 2.0,
    detectionPatterns: [/[\u4e00-\u9fff]/]
  },
  {
    code: 'ja',
    name: 'Japanese',
    tokenMultiplier: 2.5,
    detectionPatterns: [/[\u3040-\u309f\u30a0-\u30ff]/]
  },
  {
    code: 'ta',
    name: 'Tamil',
    tokenMultiplier: 4.5, // Worst case from research
    detectionPatterns: [/[\u0b80-\u0bff]/]
  },
  {
    code: 'ar',
    name: 'Arabic',
    tokenMultiplier: 3.0,
    detectionPatterns: [/[\u0600-\u06ff]/]
  }
];
```

#### Language Detector (`src/optimizer/multilingual/language-detector.ts`)

```typescript
export class LanguageDetector {
  detect(text: string): LanguageProfile {
    // Try pattern matching first (fast)
    for (const profile of LANGUAGE_PROFILES) {
      for (const pattern of profile.detectionPatterns) {
        if (pattern.test(text.slice(0, 500))) {
          return profile;
        }
      }
    }

    // Default to English
    return LANGUAGE_PROFILES[0];
  }

  /**
   * Estimate tokens with language awareness
   */
  estimateTokens(text: string, baseTokens: number): number {
    const language = this.detect(text);
    return Math.ceil(baseTokens * language.tokenMultiplier);
  }
}
```

---

### 3. Multi-Model Optimization

#### Model Profiles (`src/optimizer/models/model-profiles.ts`)

```typescript
export interface ModelProfile {
  id: string;
  name: string;
  preferredFormat: 'toon' | 'json-compact' | 'csv';
  tokenizerType: 'gpt-4' | 'claude' | 'gemini';
  supportsGrammar: boolean;
  supportsCaching: boolean;
  cachingStrategy?: 'anthropic' | 'openai';
}

export const MODEL_PROFILES: ModelProfile[] = [
  {
    id: 'claude-3-5-sonnet',
    name: 'Claude 3.5 Sonnet',
    preferredFormat: 'toon',
    tokenizerType: 'gpt-4', // Approximation
    supportsGrammar: true,
    supportsCaching: true,
    cachingStrategy: 'anthropic'
  },
  {
    id: 'claude-opus-4-5',
    name: 'Claude Opus 4.5',
    preferredFormat: 'toon',
    tokenizerType: 'gpt-4',
    supportsGrammar: true,
    supportsCaching: true,
    cachingStrategy: 'anthropic'
  },
  {
    id: 'gpt-4-turbo',
    name: 'GPT-4 Turbo',
    preferredFormat: 'json-compact', // GPT-4 optimized for JSON
    tokenizerType: 'gpt-4',
    supportsGrammar: true,
    supportsCaching: true,
    cachingStrategy: 'openai'
  },
  {
    id: 'gpt-4o',
    name: 'GPT-4o',
    preferredFormat: 'json-compact',
    tokenizerType: 'gpt-4',
    supportsGrammar: true,
    supportsCaching: true,
    cachingStrategy: 'openai'
  },
  {
    id: 'gemini-pro',
    name: 'Gemini Pro',
    preferredFormat: 'toon',
    tokenizerType: 'gpt-4', // Approximation
    supportsGrammar: true,
    supportsCaching: false
  }
];
```

#### Format Selector (`src/optimizer/models/format-selector.ts`)

```typescript
export class FormatSelector {
  selectOptimalFormat(
    data: any,
    modelId?: string
  ): 'toon' | 'json-compact' | 'csv' {
    const model = this.detectModel(modelId);

    // Use model preference if available
    if (model) {
      return model.preferredFormat;
    }

    // Fallback heuristics
    if (Array.isArray(data) && data.length > 10) {
      return 'toon'; // Best for large arrays
    }

    return 'toon'; // Default
  }

  private detectModel(modelId?: string): ModelProfile | null {
    if (!modelId) {
      // Try to detect from environment
      modelId = process.env.ANTHROPIC_MODEL ||
                process.env.CLAUDE_MODEL ||
                'claude-3-5-sonnet';
    }

    return MODEL_PROFILES.find(m =>
      m.id === modelId || modelId.includes(m.id)
    ) || null;
  }
}
```

---

### 4. Grammar-Constrained Decoding

#### TOON Grammar (`src/optimizer/grammar/toon-grammar.ts`)

```typescript
export const TOON_GRAMMAR = `
# TOON Format Grammar (BNF-style)

root ::= (statement)*
statement ::= key_value | array_def | object_def

# Key-value pairs
key_value ::= identifier ":" value

# Arrays: name[size]{fields}: row1,row2
array_def ::= identifier "[" number "]{" field_list "}:" rows
field_list ::= identifier ("," identifier)*
rows ::= row+
row ::= value ("," value)*

# Nested objects
object_def ::= identifier "." key_value

# Primitives
identifier ::= [a-zA-Z_][a-zA-Z0-9_]*
number ::= [0-9]+
value ::= [^,\n]+ | '"' [^"]* '"'
`;

export interface GrammarHints {
  format: 'toon';
  schema: string;
  examples: string[];
}

export class GrammarProvider {
  getTOONGrammar(): GrammarHints {
    return {
      format: 'toon',
      schema: TOON_GRAMMAR,
      examples: [
        'users[2]{id,name,age}: 1,Alice,30 2,Bob,25',
        'config.server.port: 8080',
        'data: value'
      ]
    };
  }
}
```

---

## üîÑ Refactored TokenOptimizer

### Enhanced `TokenOptimizer` Class

```typescript
import { CacheOptimizer } from './caching/cache-optimizer.js';
import { LanguageDetector } from './multilingual/language-detector.js';
import { FormatSelector } from './models/format-selector.js';
import { GrammarProvider } from './grammar/toon-grammar.js';

export class TokenOptimizer {
  private cacheOptimizer: CacheOptimizer;
  private languageDetector: LanguageDetector;
  private formatSelector: FormatSelector;
  private grammarProvider: GrammarProvider;

  constructor(config: EnhancedOptimizationConfig) {
    // ... existing code ...

    // NEW: Initialize advanced optimizers
    this.cacheOptimizer = new CacheOptimizer(config.caching);
    this.languageDetector = new LanguageDetector();
    this.formatSelector = new FormatSelector();
    this.grammarProvider = new GrammarProvider();
  }

  async optimize(
    content: string,
    metadata?: ToolMetadata
  ): Promise<EnhancedOptimizationResult> {
    // ... existing validation ...

    // NEW: Detect language for accurate token counting
    const baseTokens = this.tokenEncoder.encode(content).length;
    const originalTokens = this.languageDetector.estimateTokens(
      content,
      baseTokens
    );

    // ... existing structured data detection ...

    // NEW: Select optimal format based on model
    const format = this.formatSelector.selectOptimalFormat(
      structuredData.data,
      metadata?.modelId
    );

    // Convert to selected format
    let optimizedContent: string;
    switch (format) {
      case 'toon':
        optimizedContent = toonEncode(structuredData.data);
        break;
      case 'json-compact':
        optimizedContent = JSON.stringify(structuredData.data);
        break;
      case 'csv':
        optimizedContent = this.convertToCSV(structuredData.data);
        break;
    }

    // NEW: Wrap with caching structure
    const cached = this.cacheOptimizer.wrapWithCaching(
      optimizedContent,
      metadata?.toolName || 'unknown',
      structuredData.type
    );

    // NEW: Add grammar hints
    const grammar = this.grammarProvider.getTOONGrammar();

    return {
      optimized: true,
      originalContent: content,
      optimizedContent: cached.dynamicContent,
      staticPrefix: cached.staticPrefix,
      cacheBreakpoint: cached.cacheBreakpoint,
      originalTokens,
      optimizedTokens,
      savings: {
        tokens: tokenSavings,
        percentage: savingsPercentage,
        withCaching: tokenSavings * 0.9 // 90% cache hit assumption
      },
      format,
      grammar,
      language: this.languageDetector.detect(content).code
    };
  }
}
```

---

## üìä Enhanced Types

### Extended Configuration

```typescript
export interface EnhancedOptimizationConfig extends OptimizationConfig {
  caching?: CacheConfig;
  multilingual?: {
    enabled: boolean;
    defaultLanguage: string;
  };
  modelOptimization?: {
    enabled: boolean;
    preferredModel?: string;
  };
  grammar?: {
    enabled: boolean;
    includeHints: boolean;
  };
}
```

### Extended Result

```typescript
export interface EnhancedOptimizationResult extends OptimizationResult {
  staticPrefix?: string;       // Cacheable prompt prefix
  cacheBreakpoint?: boolean;    // Where cache should break
  language?: string;            // Detected language
  grammar?: GrammarHints;       // Grammar hints for output
}
```

---

## üìù Configuration Example

### New Config File: `~/.claude/toonify-config.json`

```json
{
  "enabled": true,
  "minTokensThreshold": 50,
  "minSavingsThreshold": 30,
  "skipToolPatterns": ["Bash", "Write", "Edit"],

  "caching": {
    "enabled": true,
    "provider": "auto",
    "ttl": "1hour",
    "cacheStaticPrompts": true
  },

  "multilingual": {
    "enabled": true,
    "defaultLanguage": "en"
  },

  "modelOptimization": {
    "enabled": true,
    "preferredModel": "claude-3-5-sonnet"
  },

  "grammar": {
    "enabled": true,
    "includeHints": true
  }
}
```

---

## üß™ Testing Strategy

### New Test Coverage

1. **Caching Tests** (`tests/caching.test.ts`)
   - Cache structure generation
   - Anthropic format conversion
   - OpenAI format conversion
   - Cache metrics tracking

2. **Multilingual Tests** (`tests/multilingual.test.ts`)
   - Language detection accuracy
   - Token multiplier application
   - Multi-language content handling

3. **Multi-Model Tests** (`tests/multi-model.test.ts`)
   - Model detection
   - Format selection logic
   - Model-specific optimization

4. **Grammar Tests** (`tests/grammar.test.ts`)
   - Grammar schema validation
   - Hint generation

### Integration Tests

- End-to-end optimization with all features enabled
- Performance benchmarks
- Real-world data scenarios

---

## üìà Expected Performance

### Token Savings Comparison

| Scenario | v0.2.3 | v0.3.0 | Improvement |
|----------|--------|--------|-------------|
| **JSON (English)** | 60% | 94% | +34% |
| **JSON (Multilingual)** | 60% | 95% | +35% |
| **With Caching** | N/A | 97% | - |
| **Multi-Model Optimized** | 60% | 65-95% | Varies |

### Cost Savings (100K requests/day)

| Version | Daily Cost | Annual Cost | Savings vs v0.2.3 |
|---------|-----------|-------------|-------------------|
| v0.2.3 | $100 | $36,500 | - |
| v0.3.0 (no cache) | $30 | $10,950 | $25,550 |
| v0.3.0 (with cache) | $10 | $3,650 | $32,850 |

---

## üöÄ Migration Path

### Backward Compatibility

- All v0.2.3 configs will work (defaults to old behavior)
- Opt-in for new features via config
- Existing hooks continue to work

### Breaking Changes

None - fully backward compatible!

---

## üìÖ Implementation Plan

1. **Phase 1**: Caching Integration (Days 1-2)
2. **Phase 2**: Multilingual Support (Days 2-3)
3. **Phase 3**: Multi-Model Optimization (Days 3-4)
4. **Phase 4**: Grammar Hints (Day 4)
5. **Phase 5**: Testing & Documentation (Days 5-6)
6. **Phase 6**: Release (Day 7)

---

**End of Architecture Document**
